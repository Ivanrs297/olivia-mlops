{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2702d79-c779-4e90-910c-6d5adb770472",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe55e6f-0c8d-4d09-996d-00758500412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:17<00:00, 65.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-chat-hf' #'meta-llama/Llama-2-70b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "hf_auth = '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'\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth,\n",
    "    cache_dir=\"./hub\"\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth,\n",
    "    cache_dir=\"./hub\"\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f7c08-3ea0-4e55-91bd-ded12c632990",
   "metadata": {},
   "source": [
    "Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e4f60e-3324-45f8-93b9-390098d9efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth,\n",
    "    cache_dir=\"./hub\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c1340-1d4c-438c-a1ab-79f99c020b00",
   "metadata": {},
   "source": [
    "Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc43ced1-f5a7-4852-bc9d-5d71f9d987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    #stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    max_new_tokens=512,  # mex number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25277c-0457-419c-a8f6-06fdfab45613",
   "metadata": {},
   "source": [
    "Implement LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f2f372-af14-4804-b11f-27f9168b4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c42803c-f560-445a-b421-eff460c20170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "La fusión nuclear es un proceso mediante el cual dos núcleos atómicos se unen para formar un núcleo más grande, liberando energía en el proceso. La fisión nuclear, por otro lado, es un proceso en el que un núcleo atómico se divide en dos o más núcleos más pequeños, también liberando energía.\n",
      "\n",
      "La principal diferencia entre la fusión nuclear y la fisión nuclear es que la primera produce una reacción exotérmica (caliente) mientras que la segunda produce una reacción endotérmica (fría). Además, la fusión nuclear requiere temperaturas extremadamente altas (de varios millones de grados Celsius) para activar la reacción, mientras que la fisión nuclear puede ocurrir a temperaturas más bajas.\n",
      "\n",
      "Otra diferencia importante es que la fusión nuclear produce una cantidad significativa de neutrones, lo que hace que sea difícil controlar la reacción, mientras que la fisión nuclear produce muy few neutrones.\n",
      "\n",
      "En cuanto a su potencial energético, la fusión nuclear tiene el potencial de producir una cantidad enorme de energía, pero aún no se ha logrado controlar la reacción de manera eficiente. Por otro lado, la fisión nuclear ya se utiliza en la generación de electricidad en algunas centrales eléctricas.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt=\"Explicame la diferencia entre fusion nuclear y fision nuclear.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219e4eb-705a-46ad-b3ce-e185dccedfbb",
   "metadata": {},
   "source": [
    "## Probando con formato de subtítulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "06300117-aa22-4485-8a4a-9598eac50aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./diari/F-285.srt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf027d-5fdc-4441-a8f1-901b12f60134",
   "metadata": {},
   "source": [
    "Borrar identificador de speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "08a53735-a1d7-43cc-ab11-2b8de48448a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.page_content = doc.page_content.replace(\"[SPEAKER_00]: \", \"\")\n",
    "    doc.page_content = doc.page_content.replace(\"[SPEAKER_01]: \", \"\")\n",
    "    doc.page_content = doc.page_content.replace(\"[SPEAKER_02]: \", \"\")\n",
    "    # print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e0474a6f-fe41-49b8-8a09-01a0977270f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3e8a270f-a65b-4963-9533-aca16d771a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a0d04084-375e-4418-9e7a-68c6b6837f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5e72dcca-32cc-4d2f-9daa-9165223b519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' La fecha de nacimiento de la persona que está siendo entrevistada es el 19 de septiembre de 1982. Se puede inferir esto a partir de la información proporcionada en la entrevista, específicamente en la pregunta 8, donde se dice que la entrevistada nació en México el 19 de septiembre de 1982.'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es la fecha de nacimiento de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "13b795b2-d465-4708-a43e-aff7e7ed7f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the transcript, the name of the person being interviewed is Estefanía. This can be inferred from the dialogue in lines 121-122, where she introduces herself as \"Estefanía\" and from the subsequent references to her by that name throughout the transcript.'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es el nombre de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c38c4-1263-4698-a326-496050af9f41",
   "metadata": {},
   "source": [
    "Probando custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7374300c-2d54-4f7c-b9f9-cb266f9d2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context, coming from an interview, to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in Spanish:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "84c92124-1e3d-44e9-a561-e691b3001953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' El nombre de la persona que está siendo entrevistada es Estefanía.'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es el nombre de la persona que está siendo entrevistada?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5a492a21-9a28-47a0-937a-f37d5c4918f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' La fecha de nacimiento de la persona que está siendo entrevistada es el 19 de septiembre de 1982.'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cuál es la fecha de nacimiento de la persona que está siendo entrevistada?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8cdba-3cd6-4f87-bf21-5d457ba54114",
   "metadata": {},
   "source": [
    "## Probando con diálogos generados de la transcripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2c49d075-76f7-403b-a373-c8608a461d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a60eaca6-9c40-4d20-8e7a-7e3eb5ef4d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gracias.',\n",
       " 'Gracias a ti, Estefanía.',\n",
       " 'Entonces, como te compartía, vamos a aperturar un expediente.']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./diari/F-285.srt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "lines = [part.split(\"]: \")[-1] for num, part in enumerate(text.split(\"\\n\\n\"))]\n",
    "lines[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d077d7-4ec3-46d7-bce7-acbfb2bc0169",
   "metadata": {},
   "source": [
    "Diálogos con contexto de dos líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f3c9fc5e-1485-4aa5-9206-76ec6b6985f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = []\n",
    "i = 0\n",
    "prev = None\n",
    "prevText = \"\"\n",
    "curr = \"\"\n",
    "while i < len(lines):\n",
    "    curr_type = \"question\" if \"¿\" in lines[i] or \"?\" in lines[i] else \"text\"\n",
    "    # if current line has a question\n",
    "    if curr_type == \"question\":\n",
    "        # if the prev line had only text\n",
    "        if prev == \"text\":\n",
    "            dialogues.append(curr)\n",
    "            curr = \"\"\n",
    "    # add current text to curr\n",
    "    curr = curr + \" \" + lines[i]\n",
    "\n",
    "    # set prev\n",
    "    prev = curr_type\n",
    "    \n",
    "    # increment i\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d8365e9b-5dc9-4082-9de4-a3ee274ebfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gracias. Gracias a ti, Estefanía. Entonces, como te compartía, vamos a aperturar un expediente. donde se te van a tomar datos personales los cuales se quedan resguardados de manera confidencial aquí en la unidad y también que me compartas que te traía acá con nosotros yo voy a iniciar a aplicar esta entrevista si tú tienes alguna duda me lo puedes comentar en cualquier momento aparte de lo que te referí respecto a nuestros servicios estos tampoco se te van a cobrar no gracias a ti me interesa saber si traes alguna lesión o alguna emergencia médica \n",
      "\n",
      " ¿Te encuentras embarazada en este momento? No. \n",
      "\n",
      " ¿Cuál es tu fecha de nacimiento? 19 de septiembre del 82. \n",
      "\n",
      " ¿Te identificas como femenina, mujer? Sí. Gracias. \n",
      "\n",
      " ¿Tu nacionalidad? ¿Dónde es que tú naciste? Nací en México, soy mexicana. \n",
      "\n",
      " Y bueno, nací... ¿En qué estado? Nací en la Ciudad de México hace un día que no estaba de vacaciones. \n",
      "\n",
      " ¿Por la suerte? Sí. Toda mi vida he vivido aquí. Radicas entonces entidad federativa Jalisco. Sí. El teléfono que tomé de tu registro 33 18 79 60 79 me interesa preguntarte si podemos darte seguimiento vía whatsapp y telefónica en caso de ser necesario. Sí. Muchas gracias. De tu domicilio, calle Campo Castillo, número 1139. \n",
      "\n",
      " ¿Cuáles son los cruces de tu domicilio? Creo que es Campo Real Oriente y el otro no me acuerdo honestamente. No te preocupes. \n",
      "\n",
      " ¿Alguna referencia para ubicar mejor tu casa? Enfrente del Coto Fátima. Tome de tu registro que es en el estado de Jalisco, municipio de Zapopar, colonia o localidad, Campo Real. Sí, es fraccionamiento Campo Real. Ok, le vamos a leer qué es fraccionamiento. Gracias. \n",
      "\n",
      " ¿Tu escolaridad cuál es? He estudiado una maestría en el extranjero pero todavía no la he homologado. Mi licenciatura y maestría me becaron en otro país. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in dialogues[:10]:\n",
    "    print(d, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f6cfe1e5-3ff4-4b39-903b-68e3b483daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_texts(dialogues, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de7931-c190-4414-94f5-e72f78dca472",
   "metadata": {},
   "source": [
    "Prueba sin prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "667b68a0-5e2a-41f5-9c5e-26012329b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "016d7f5a-3527-41ae-bbbe-2acd6a969aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' La fecha de nacimiento de la persona que está siendo entrevistada es el 19 de septiembre del 82, ya que se mencionó en la conversación anterior.'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es la fecha de nacimiento de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "921d096f-9a32-474a-960a-0c4ee38dace0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the information provided, the name of the person being interviewed is not explicitly stated. However, based on the context, it can be inferred that the person being interviewed is the one who is asking the questions and is seeking employment, as they mention their \"pareja\" (partner) and refer to themselves in the first person. Therefore, the name of the person being interviewed is not known.'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es el nombre de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44448bb-3d46-4387-9e0a-afb2e3722eeb",
   "metadata": {},
   "source": [
    "Prueba con custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "085d7174-36a3-4e1c-ad7e-49cc5682e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(), chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "462c1f1f-0769-4ba4-8444-aebef0203453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLa fecha de nacimiento de la persona que está siendo entrevistada es el 19 de septiembre del 82, ya que ella misma lo ha mencionado en la entrevista.'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es la fecha de nacimiento de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fcfacccf-164f-4119-8247-be6ae26b8835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nBased on the information provided in the interview, the name of the person being interviewed is not explicitly stated. However, based on the context, it can be inferred that the person being interviewed is the one who is asking for the job, as they are the ones conducting the interview and asking questions. Therefore, the name of the person being interviewed is not known.'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es el nombre de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f6b9b-2928-4604-9d09-b3c496e8511f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
