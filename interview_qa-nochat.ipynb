{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2702d79-c779-4e90-910c-6d5adb770472",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe55e6f-0c8d-4d09-996d-00758500412c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:17<00:00, 65.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-hf' #'meta-llama/Llama-2-70b-chat-hf'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# begin initializing HF items, need auth token for these\n",
    "hf_auth = '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'\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth,\n",
    "    cache_dir=\"./hub\"\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    use_auth_token=hf_auth,\n",
    "    cache_dir=\"./hub\"\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f7c08-3ea0-4e55-91bd-ded12c632990",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e4f60e-3324-45f8-93b9-390098d9efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth,\n",
    "    cache_dir=\"./hub\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c1340-1d4c-438c-a1ab-79f99c020b00",
   "metadata": {},
   "source": [
    "Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7acaf5-dcf1-4294-a4d9-0c2d625948f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = ['\\nHuman:', '\\n```\\n', '\\n']\n",
    "\n",
    "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
    "stop_token_ids\n",
    "\n",
    "import torch\n",
    "\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
    "stop_token_ids\n",
    "\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "# define custom stopping criteria object\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc43ced1-f5a7-4852-bc9d-5d71f9d987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    max_new_tokens=512,  # mex number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25277c-0457-419c-a8f6-06fdfab45613",
   "metadata": {},
   "source": [
    "Implement LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f2f372-af14-4804-b11f-27f9168b4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c42803c-f560-445a-b421-eff460c20170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### 2014\n",
      "\n",
      "* 1 de enero: ¿Qué es el cáncer?\n",
      "* 8 de enero: ¿Cómo se mide la temperatura en el espacio?\n",
      "* 15 de enero: ¿Por qué no podemos ver las estrellas durante el día?\n",
      "* 22 de enero: ¿Cuál es la diferencia entre un planeta y una estrella?\n",
      "* 29 de enero: ¿Cuál es la diferencia entre un asteroide y un cometa?\n",
      "* 5 de febrero: ¿Cuál es la diferencia entre un satélite natural y un satélite artificial?\n",
      "* 12 de febrero: ¿Cuál es la diferencia entre un meteorito y una estrella fugaz?\n",
      "* 19 de febrero: ¿Cuál es la diferencia entre un meteoroide y un cometa?\n",
      "* 26 de febrero: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 5 de marzo: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 12 de marzo: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 19 de marzo: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 26 de marzo: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 2 de abril: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 9 de abril: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 16 de abril: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 23 de abril: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 30 de abril: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 7 de mayo: ¿Cuál es la diferencia entre un meteoro y un cometa?\n",
      "* 14 de mayo: ¿Cuál es la diferencia entre un meteoro y un\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt=\"Explicame la diferencia entre fusion nuclear y fision nuclear.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219e4eb-705a-46ad-b3ce-e185dccedfbb",
   "metadata": {},
   "source": [
    "# Test 1: Subtítulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "06300117-aa22-4485-8a4a-9598eac50aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./diari/F-285.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf027d-5fdc-4441-a8f1-901b12f60134",
   "metadata": {},
   "source": [
    "Borrar identificador de speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08a53735-a1d7-43cc-ab11-2b8de48448a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.page_content = doc.page_content.replace(\"[SPEAKER_00]: \", \"\")\n",
    "    doc.page_content = doc.page_content.replace(\"[SPEAKER_01]: \", \"\")\n",
    "    doc.page_content = doc.page_content.replace(\"[SPEAKER_02]: \", \"\")\n",
    "    # print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e0474a6f-fe41-49b8-8a09-01a0977270f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3e8a270f-a65b-4963-9533-aca16d771a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d7118ead-72ea-43ff-9205-2206e3e282f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"¿Cuál es el nombre de la persona que está siendo entrevistada?\",\n",
    "    \"¿Cuál es la fecha de nacimiento de la persona que está siendo entrevistada?\",\n",
    "    \"¿En dónde nació la persona que está siendo entrevistada?\",\n",
    "    \"Cuál es su teléfono de contacto de la persona que está siendo entrevistada?\",\n",
    "    \"¿Cuál es la edad de la persona que está siendo entrevistada?\",\n",
    "    \"¿Cuál es el domicilio de Estefania?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872717a-ddd9-41ba-86f6-8586feea49d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sin usar prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d04084-375e-4418-9e7a-68c6b6837f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f06743a7-c6b0-4b7a-bedf-5b05577d796c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.1 s ± 75 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit qa.run(\"¿Cual es la fecha de nacimiento de la persona que está siendo entrevistada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa44b258-e977-4d2d-91de-6a50d5c2823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ¿Cuál es el nombre de la persona que está siendo entrevistada?\n",
      "A: Estefanía\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ¿Cuál es la fecha de nacimiento de la persona que está siendo entrevistada?\n",
      "A: The date of birth is September 19th, 1982.\n",
      "\n",
      "\n",
      "Q: ¿En dónde nació la persona que está siendo entrevistada?\n",
      "A: The person being interviewed was born in Mexico City.\n",
      "\n",
      "\n",
      "Q: Cuál es su teléfono de contacto de la persona que está siendo entrevistada?\n",
      "A: 33 18 79 60 79\n",
      "\n",
      "\n",
      "Q: ¿Cuál es la edad de la persona que está siendo entrevistada?\n",
      "A: The age of the person being interviewed is 18 years old.\n",
      "\n",
      "\n",
      "Q: ¿Cuál es el domicilio de Estefania?\n",
      "A: The address is 123 Main Street, Anytown, USA.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in questions:\n",
    "    answer = qa.run(query)\n",
    "    answer = answer.split(\"\\n\")[0].strip()\n",
    "    print(\"Q:\", query)\n",
    "    print(\"A:\", answer)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c38c4-1263-4698-a326-496050af9f41",
   "metadata": {},
   "source": [
    "#### Usando custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7374300c-2d54-4f7c-b9f9-cb266f9d2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_INST, E_INST = \"\", \"\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "instruction = B_INST + \"\"\"Use ONLY the following pieces of context (coming from an interview) to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\" + E_INST\n",
    "\n",
    "prompt_template = instruction + \"\"\"\n",
    "Answer in Spanish:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "607217c4-17a3-40e6-a119-a15fbd82a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 5}),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    # verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5b270a85-7aa4-41dd-9b46-178192425818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ¿Cuál es el nombre de la persona que está siendo entrevistada?\n",
      "A: Estefanía.\n",
      "\n",
      "\n",
      "Q: ¿Cuál es la fecha de nacimiento de la persona que está siendo entrevistada?\n",
      "A: 19 de septiembre del 82.\n",
      "\n",
      "\n",
      "Q: ¿En dónde nació la persona que está siendo entrevistada?\n",
      "A: Nací en México, soy mexicana.\n",
      "\n",
      "\n",
      "Q: Cuál es su teléfono de contacto de la persona que está siendo entrevistada?\n",
      "A: 33 18 79 60 79\n",
      "\n",
      "\n",
      "Q: ¿Cuál es la edad de la persona que está siendo entrevistada?\n",
      "A: \"I am 38 years old.\"\n",
      "\n",
      "\n",
      "Q: ¿Cuál es el domicilio de Estefania?\n",
      "A: \"Campo Real, Colonia Campo Real.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in questions:\n",
    "    answer = qa.run(query)\n",
    "    answer = answer.split(\"\\n\")[0].strip()\n",
    "    print(\"Q:\", query)\n",
    "    print(\"A:\", answer)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4e7e4ac8-d61d-49a8-b324-5d2fac260550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"Soy licenciada en derecho.\"\\n\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n¿Y después acudiste a medios alternos o antes?\\nAntes.\\n¿Cuándo?\\nHace tres meses.\\n¿Y después acudiste a la Fiscalía?\\nSí.\\n'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"¿cual es el estatus de la escolaridad que tiene la persona entrevistada?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aa5ee581-5ebb-49d7-8da0-2ef81d6c9a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "A su vez también voy a solicitar el servicio de un abogado o abogada.\n",
      "para que nos apoye con tu asesoría.\n",
      "¿Cómo es que tú te enteraste de nuestros servicios?\n",
      "Porque acudí a la Centro de Igualdad Sustentiva de Enredo.\n",
      "Ah, ok.\n",
      "¿Lo viste en internet?\n",
      "Lo vi en internet.\n",
      "Es que allá son oficinas administrativas y aquí la trata de atención.\n",
      "Muy bien.\n",
      "Te paso entonces para que me regales estas firmas, ¿va?\n",
      "Nombre y firma, nombre, fecha y firma.\n",
      "Nombre, nombre y firma.\n",
      "Nombre, fecha y firma.\n",
      "Si tienes duda, de todas maneras me lo dices.\n",
      "Yo aquí estoy.\n",
      "--------\n",
      "Ese mismo día, se le mandó la carpeta a medios alternos y después, una semana después más o menos, me llamaron para presentarnos para entablar la renegociación que mi padrastro declinó.\n",
      "El problema es que\n",
      "Bueno, además de la malversación del fondo y todo lo que pasó es que mi madre está de su parte y mi hermano es abogado y creo que él lo está asesorando y puede incluso ir en mi contra.\n",
      "Y mi hermano trabajó en la fiscalía y tengo miedo de que él interfiera\n",
      "en el proceso que pueda incluso sobornar o utilizar sus conexiones porque él trabajó allí.\n",
      "¿Allí en calle 14?\n",
      "Él trabajó en patrimoniales, en varias agencias.\n",
      "Y además han hecho una invitación más o menos muy\n",
      "indirecta a que desista de los cargos y me van a hacer que mi pareja sea deportada.\n",
      "Y me acusan de falsedad de declaración, o sea, quisieran acusarme de falsedad de declaración.\n",
      "Yo lo que quisiera es tratar de hacer las cosas por medio de justicia alternativa o algo para, para no entrar en un conflicto mayor\n",
      "porque obviamente aunque mi mamá no me apoye pues no quisiera afectarla tanto\n",
      "Dentro de estas amenazas o digamos intimidación, últimos episodios de violencia, ¿hace cuánto fueron más o menos?\n",
      "Pues fue la semana pasada que tuve la conversación con mi hermano, pero no el abogado, el otro.\n",
      "Y sí me molesté y hubo como una interacción bastante fuerte, porque yo no puedo creer que prefieran apoyar a una persona que me defraudo.\n",
      "--------\n",
      "Tome de tu registro que es en el estado de Jalisco, municipio de Zapopar, colonia o localidad, Campo Real.\n",
      "Sí, es fraccionamiento Campo Real.\n",
      "Ok, le vamos a leer qué es fraccionamiento.\n",
      "Gracias.\n",
      "¿Tu escolaridad cuál es?\n",
      "He estudiado una maestría en el extranjero pero todavía no la he homologado.\n",
      "Mi licenciatura y maestría me becaron en otro país.\n",
      "¿Está inconcluso?\n",
      "No, no está inconcluso, solo que no lo he homologado.\n",
      "Por lo que entiendo no puedo ostentar un título que no está homologado hasta que esté homologado.\n",
      "Pero en otro país tengo maestría.\n",
      "¿Tienes seguridad social en este momento?\n",
      "¿A qué te dedicas actualmente?\n",
      "Soy cantante profesional.\n",
      "¿Tu estado civil?\n",
      "Vivo con mi pareja, pero no estoy casada.\n",
      "¿Desde hace cuánto tiempo vives en un hogar libre?\n",
      "Cuatro años.\n",
      "Un poco más de cuatro años.\n",
      "¿Viven en casa propia, rentada, prestada o compartida?\n",
      "Compartida con mi papá.\n",
      "¿La venta?\n",
      "No, la casa recién, esa de mi papá.\n",
      "¿Cuántas personas viven en ese domicilio?\n",
      "Tres.\n",
      "¿El mayor de las personas que viven ahí es tu papá?\n",
      "¿Qué edad tiene él?\n",
      "Mi papá es de 55.\n",
      "Debería tener unos 67 más o menos.\n",
      "¿Tiene él alguna discapacidad?\n",
      "No, gracias a Dios sí.\n",
      "¿Es dependiente económico tuyo?\n",
      "No.\n",
      "¿Quién es la otra persona que vive ahí?\n",
      "Mi pareja.\n",
      "¿Qué edad tiene él?\n",
      "Cuarenta y uno.\n",
      "¿Tiene alguna discapacidad?\n",
      "No.\n",
      "¿Es dependiente económico tuyo?\n",
      "Pues ahora más o menos, por todo el problema que le hemos arrastrado.\n",
      "Pero pues compartimos los gastos.\n",
      "Alguien más que vive ahí y tú, ¿verdad?\n",
      "Sí.\n",
      "--------\n",
      "Y el MP también me dijo que dado caso de que él no se presentara, entonces ya me tocaba volver a integrar la carteta con todo lo que ya tenía y declarar todo lo que tengo ahora.\n",
      "Pero no sé exactamente cómo hacerlo.\n",
      "Ah, ok.\n",
      "Ahorita te voy a derivar al área jurídica si te parece bien.\n",
      "Para que te brinden asesoría respecto a las opciones que puedas tener.\n",
      "Voy a terminar de recabar datos y pasamos a ese servicio.\n",
      "Una pregunta.\n",
      "La verdad es que me he afectado muchísimo porque estoy en una situación muy tensa.\n",
      "¿También aquí dan como alguna asesoría?\n",
      "Asesoría, claro que sí, en cuestión de asesoría de primera vez sí, no se llevan a cabo seguimientos por ahorita, pero te puedo pasar a psicología también.\n",
      "Ahorita el servicio, en especial el día de hoy, está un poco saturado porque tenemos pocas psicólogas y aparte hoy menos una.\n",
      "Este solo son dos, lo consideraría a tus tiempos y a los tiempos de la psicóloga según la espera que haya, pero si gustas te paso primero con un abogado para no tardarte, ¿sale?\n",
      "Y ya lo vemos, pero hacia adelante.\n",
      "O si gustas venir mañana o pasado, cualquier día puedes venir a tomar ese servicio de psicología también.\n",
      "Ok, gracias.\n",
      "¿Cómo se llama tu padrastro?\n",
      "José Ángel Ramírez Gómez.\n",
      "¿Qué edad tiene él?\n",
      "Pues creo que está por allí de los 79 años.\n",
      "¿Hace cuánto tienes tu contacto o interacción con él?\n",
      "¿Hace cuántos años?\n",
      "¿Que lo conozco?\n",
      "Pues más de 25 años.\n",
      "Tiene aproximadamente 20 años casado con mi mamá.\n",
      "Más los que estaban juntos.\n",
      "¿Su domicilio?\n",
      "--------\n",
      "Gracias.\n",
      "Gracias a ti, Estefanía.\n",
      "Entonces, como te compartía, vamos a aperturar un expediente.\n",
      "donde se te van a tomar datos personales los cuales se quedan resguardados de manera confidencial aquí en la unidad y también que me compartas que te traía acá con nosotros yo voy a iniciar a aplicar esta entrevista si tú tienes alguna duda me lo puedes comentar en cualquier momento aparte de lo que te referí respecto a nuestros servicios estos tampoco se te van a cobrar no gracias a ti me interesa saber si traes alguna lesión o alguna emergencia médica\n",
      "¿Te encuentras embarazada en este momento?\n",
      "No.\n",
      "¿Cuál es tu fecha de nacimiento?\n",
      "19 de septiembre del 82.\n",
      "¿Te identificas como femenina, mujer?\n",
      "Sí.\n",
      "Gracias.\n",
      "¿Tu nacionalidad?\n",
      "¿Dónde es que tú naciste?\n",
      "Nací en México, soy mexicana.\n",
      "Y bueno, nací... ¿En qué estado?\n",
      "Nací en la Ciudad de México hace un día que no estaba de vacaciones.\n",
      "¿Por la suerte?\n",
      "Sí.\n",
      "Toda mi vida he vivido aquí.\n",
      "Radicas entonces entidad federativa Jalisco.\n",
      "Sí.\n",
      "El teléfono que tomé de tu registro 33 18 79 60 79 me interesa preguntarte si podemos darte seguimiento vía whatsapp y telefónica en caso de ser necesario.\n",
      "Sí.\n",
      "Muchas gracias.\n",
      "De tu domicilio, calle Campo Castillo, número 1139.\n",
      "¿Cuáles son los cruces de tu domicilio?\n",
      "Creo que es Campo Real Oriente y el otro no me acuerdo honestamente.\n",
      "No te preocupes.\n",
      "¿Alguna referencia para ubicar mejor tu casa?\n",
      "Enfrente del Coto Fátima.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "ps = docsearch.as_retriever(search_kwargs={'k': 5}).get_relevant_documents(\"¿que escolaridad tiene?\")\n",
    "print(len(ps))\n",
    "for p in ps:\n",
    "    print(p.page_content)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2c49d075-76f7-403b-a373-c8608a461d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a60eaca6-9c40-4d20-8e7a-7e3eb5ef4d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gracias.',\n",
       " 'Gracias a ti, Estefanía.',\n",
       " 'Entonces, como te compartía, vamos a aperturar un expediente.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./diari/F-285.srt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "lines = [part.split(\"]: \")[-1] for num, part in enumerate(text.split(\"\\n\\n\"))]\n",
    "lines[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d077d7-4ec3-46d7-bce7-acbfb2bc0169",
   "metadata": {},
   "source": [
    "Diálogos con contexto de dos líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3c9fc5e-1485-4aa5-9206-76ec6b6985f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = []\n",
    "i = 0\n",
    "prev = None\n",
    "prevText = \"\"\n",
    "curr = \"\"\n",
    "while i < len(lines):\n",
    "    curr_type = \"question\" if \"¿\" in lines[i] or \"?\" in lines[i] else \"text\"\n",
    "    # if current line has a question\n",
    "    if curr_type == \"question\":\n",
    "        # if the prev line had only text\n",
    "        if prev == \"text\":\n",
    "            dialogues.append(curr)\n",
    "            curr = \"\"\n",
    "    # add current text to curr\n",
    "    curr = curr + \" \" + lines[i]\n",
    "\n",
    "    # set prev\n",
    "    prev = curr_type\n",
    "    \n",
    "    # increment i\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8365e9b-5dc9-4082-9de4-a3ee274ebfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gracias. Gracias a ti, Estefanía. Entonces, como te compartía, vamos a aperturar un expediente. donde se te van a tomar datos personales los cuales se quedan resguardados de manera confidencial aquí en la unidad y también que me compartas que te traía acá con nosotros yo voy a iniciar a aplicar esta entrevista si tú tienes alguna duda me lo puedes comentar en cualquier momento aparte de lo que te referí respecto a nuestros servicios estos tampoco se te van a cobrar no gracias a ti me interesa saber si traes alguna lesión o alguna emergencia médica \n",
      "\n",
      " ¿Te encuentras embarazada en este momento? No. \n",
      "\n",
      " ¿Cuál es tu fecha de nacimiento? 19 de septiembre del 82. \n",
      "\n",
      " ¿Te identificas como femenina, mujer? Sí. Gracias. \n",
      "\n",
      " ¿Tu nacionalidad? ¿Dónde es que tú naciste? Nací en México, soy mexicana. \n",
      "\n",
      " Y bueno, nací... ¿En qué estado? Nací en la Ciudad de México hace un día que no estaba de vacaciones. \n",
      "\n",
      " ¿Por la suerte? Sí. Toda mi vida he vivido aquí. Radicas entonces entidad federativa Jalisco. Sí. El teléfono que tomé de tu registro 33 18 79 60 79 me interesa preguntarte si podemos darte seguimiento vía whatsapp y telefónica en caso de ser necesario. Sí. Muchas gracias. De tu domicilio, calle Campo Castillo, número 1139. \n",
      "\n",
      " ¿Cuáles son los cruces de tu domicilio? Creo que es Campo Real Oriente y el otro no me acuerdo honestamente. No te preocupes. \n",
      "\n",
      " ¿Alguna referencia para ubicar mejor tu casa? Enfrente del Coto Fátima. Tome de tu registro que es en el estado de Jalisco, municipio de Zapopar, colonia o localidad, Campo Real. Sí, es fraccionamiento Campo Real. Ok, le vamos a leer qué es fraccionamiento. Gracias. \n",
      "\n",
      " ¿Tu escolaridad cuál es? He estudiado una maestría en el extranjero pero todavía no la he homologado. Mi licenciatura y maestría me becaron en otro país. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in dialogues[:10]:\n",
    "    print(d, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6cfe1e5-3ff4-4b39-903b-68e3b483daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_texts(dialogues, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de7931-c190-4414-94f5-e72f78dca472",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Prueba sin prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "667b68a0-5e2a-41f5-9c5e-26012329b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "016d7f5a-3527-41ae-bbbe-2acd6a969aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"¿Cual es la fecha de nacimiento de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "# qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "921d096f-9a32-474a-960a-0c4ee38dace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"¿Cual es el nombre de la persona que está siendo entrevistada? Justifica tu respuesta\"\n",
    "# qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44448bb-3d46-4387-9e0a-afb2e3722eeb",
   "metadata": {},
   "source": [
    "#### Prueba con custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8565814e-fbed-4056-b4bb-eeb7d1c38d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"De acuerdo con los siguientes extractos de una entrevista:\n",
    "\n",
    "{context}\n",
    "\n",
    "Contesta la siguiente pregunta:\n",
    "{question}\n",
    "\n",
    "La respuesta es:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "085d7174-36a3-4e1c-ad7e-49cc5682e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "462c1f1f-0769-4ba4-8444-aebef0203453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'La fecha de nacimiento de la persona que está siendo entrevistada',\n",
       " 'result': ' 19 de septiembre del 82.\\n\\n### 2013\\n\\nEn 2013, el programa se renovó y cambió su nombre a \"El Show de los Sueños\", donde se presentan nuevas pruebas para llegar al sueño. El programa fue conducido por el mismo conductor, pero con un nuevo panel de jurados.\\n\\n### 2014\\n\\nEn 2014, el programa se renovó y cambió su nombre a \"El Show de los Sueños\" donde se presentan nuevas pruebas para llegar al sueño. El programa fue conducido por el mismo conductor, pero con un nuevo panel de jurados.\\n\\n### 2015\\n\\nEn 2015, el programa se renovó y cambió su nombre a \"El Show de los Sueños\" donde se presentan nuevas pruebas para llegar al sueño. El programa fue conducido por el mismo conductor, pero con un nuevo panel de jurados.\\n\\n### 2016\\n\\nEn 2016, el programa se renovó y cambió su nombre a \"El Show de los Sueños\" donde se presentan nuevas pruebas para llegar al sueño. El programa fue conducido por el mismo conductor, pero con un nuevo panel de jurados.\\n\\n### 2017\\n\\nEn 2017, el programa se renovó y cambió su nombre a \"El Show de los Sueños\" donde se presentan nuevas pruebas para llegar al sueño. El programa fue conducido por el mismo conductor, pero con un nuevo panel de jurados.\\n\\n### 2018\\n\\nEn 2018, el programa se renovó y cambió su nombre a \"El Show de los Sueños\" donde se presentan nuevas pruebas para llegar al sueño. El programa fue conducido por el mismo conductor, pero con un nuevo panel de jurados.\\n\\n### 2019\\n\\nEn 2019, el programa se renovó y cambió su nombre a \"El Show de los Sueños\" donde se presentan nuevas pruebas para llegar al sueño. El programa fue conducido por el mismo conductor, pero con un nuevo panel de jur',\n",
       " 'source_documents': [Document(page_content=' ¿Me compartías entonces que el motivo de la tensión es por tu pareja? No.', metadata={}),\n",
       "  Document(page_content=' ¿Tienes seguridad social en este momento? ¿A qué te dedicas actualmente? Soy cantante profesional.', metadata={}),\n",
       "  Document(page_content=' ¿Quién es la otra persona que vive ahí? Mi pareja.', metadata={}),\n",
       "  Document(page_content=' ¿Cuál es tu fecha de nacimiento? 19 de septiembre del 82.', metadata={})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"La fecha de nacimiento de la persona que está siendo entrevistada\"\n",
    "qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcfacccf-164f-4119-8247-be6ae26b8835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'El nombre de la persona que está siendo entrevistada',\n",
       " 'result': '\\n\\n¿Qué es lo que más te gusta hacer cuando estás libre?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n\\n¿Por qué no me has dicho que eres gay?\\n',\n",
       " 'source_documents': [Document(page_content=' ¿Cuántas personas viven en ese domicilio? Tres.', metadata={}),\n",
       "  Document(page_content=' ¿Quién es la otra persona que vive ahí? Mi pareja.', metadata={}),\n",
       "  Document(page_content=' ¿Tienes seguridad social en este momento? ¿A qué te dedicas actualmente? Soy cantante profesional.', metadata={}),\n",
       "  Document(page_content=' ¿Me compartías entonces que el motivo de la tensión es por tu pareja? No.', metadata={})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"¿Cual es la edad de Estefania?\"\n",
    "qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83650dc7-3604-421f-b85d-1e148f1618fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c7f81-c081-4ca6-9837-e40a7dda621d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
